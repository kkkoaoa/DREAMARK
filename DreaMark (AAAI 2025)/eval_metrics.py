from sentence_transformers import util, SentenceTransformer
from PIL import Image

if __name__ == "__main__":
    # acc = [0.5625, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.625, 0.5, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.6875, 0.625, 0.6875, 0.75, 0.6875, 0.75, 0.625, 0.625, 0.75, 0.6875, 0.625, 0.75, 0.75, 0.6875, 0.75, 0.75, 0.75, 0.75, 0.6875, 0.6875, 0.6875, 0.625, 0.6875, 0.6875, 0.6875, 0.75, 0.6875, 0.6875, 0.625, 0.6875, 0.6875, 0.625, 0.625, 0.625, 0.75, 0.6875, 0.6875, 0.75, 0.75, 0.75, 0.6875, 0.6875, 0.625, 0.75, 0.625, 0.6875, 0.6875, 0.625, 0.6875, 0.5625, 0.625, 0.625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5, 0.625, 0.6875, 0.6875, 0.625, 0.625, 0.6875, 0.6875, 0.6875, 0.625, 0.6875, 0.625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.6875, 0.5625, 0.625, 0.8125, 0.625, 0.75, 0.6875, 0.75, 0.6875, 0.75, 0.75, 0.75, 0.8125, 0.8125, 0.75, 0.75, 0.8125, 0.8125, 0.75, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.875, 0.8125, 0.75, 0.6875, 0.75, 0.6875, 0.75, 0.75, 0.75, 0.875, 0.75, 0.8125, 0.8125, 0.8125, 0.875, 0.875, 0.75, 0.875, 0.75, 0.875, 0.8125, 0.75, 0.8125, 0.8125, 0.8125, 0.875, 0.75, 0.875, 0.875, 0.8125, 0.75, 0.8125, 0.9375, 0.8125, 0.75, 0.9375, 0.8125, 0.8125, 0.875, 0.8125, 0.8125, 0.75, 0.8125, 0.8125, 0.75, 0.75, 0.75, 0.75, 0.8125, 0.75, 0.75, 0.8125, 0.75, 0.75, 0.75, 0.625, 0.6875, 0.625, 0.625, 0.6875, 0.625, 0.625, 0.625, 0.6875, 0.6875, 0.625, 0.6875, 0.6875, 0.6875, 0.625, 0.6875, 0.625, 0.625, 0.625, 0.5625, 0.5, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.625, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5625, 0.5625, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5625, 0.5625, 0.625, 0.5625, 0.625, 0.5, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.625, 0.5625, 0.75, 0.625, 0.625, 0.6875, 0.625, 0.6875, 0.6875, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5, 0.5625, 0.5625, 0.625, 0.625, 0.5625, 0.625, 0.5, 0.5, 0.5625, 0.5, 0.625, 0.5625, 0.625, 0.5625, 0.625, 0.625, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5, 0.5, 0.625, 0.5, 0.5625, 0.5, 0.5, 0.625, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.625, 0.625, 0.5625, 0.6875, 0.6875, 0.5625, 0.625, 0.5625, 0.625, 0.625, 0.5625, 0.5, 0.5625, 0.5625, 0.625, 0.6875, 0.75, 0.5625, 0.5625, 0.5, 0.5625, 0.625, 0.6875, 0.6875, 0.6875, 0.75, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.625, 0.5625, 0.625, 0.625, 0.5625, 0.5, 0.5625, 0.625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.5, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5625, 0.5, 0.5, 0.5, 0.625, 0.625, 0.5625, 0.5, 0.5625, 0.625, 0.625, 0.5625, 0.5, 0.625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.625, 0.625, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.75, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.75, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.625, 0.6875, 0.625, 0.625, 0.625, 0.6875, 0.625, 0.625, 0.625, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.625, 0.6875, 0.6875, 0.625, 0.625, 0.6875, 0.6875, 0.5625, 0.5625, 0.625, 0.5625, 0.625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.5625, 0.6875, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.625, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5625, 0.5625, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.625, 0.5, 0.625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5, 0.5625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.625, 0.625, 0.5625, 0.625, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5625, 0.4375, 0.5625, 0.4375, 0.625, 0.5625, 0.4375, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.4375, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5625, 0.5, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.6875, 0.5625, 0.5625, 0.625, 0.625, 0.5625, 0.5625, 0.5, 0.5, 0.5625, 0.5625, 0.5625, 0.5, 0.5625, 0.5, 0.5, 0.5625, 0.625, 0.625, 0.6875, 0.625, 0.5625, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.5625, 0.5625, 0.5625, 0.5, 0.5, 0.625, 0.5, 0.5625, 0.5625, 0.5625, 0.5, 0.5625, 0.5625, 0.5, 0.625, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5, 0.5625, 0.5, 0.5, 0.5625, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5625, 0.625, 0.625, 0.5625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.5625, 0.5625, 0.625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.625, 0.625, 0.625, 0.5625, 0.625, 0.5625, 0.5625, 0.5, 0.625, 0.5, 0.5625, 0.5625, 0.5625, 0.5, 0.5, 0.5, 0.5, 0.5]
    # print(sum(acc)/len(acc))
    # exit()
    text = "a DSLR photo of peacock."

    model = SentenceTransformer("clip-ViT-B-16", local_files_only=True)

    img_emb = model.encode(Image.open(f'exp-dmtet-stage3/2024-08-14-a-DSLR-photo-of-peacock.-16-1000-scale-7.5-lr-0.001-albedo-le-10-render-512-cube-sd-2.1-5000-finetune-tet-256/validation/df_ep000160-mark-albedo0.png'))

    #Encode text descriptions
    text_emb = model.encode([text])

    #Compute cosine similarities
    cos_scores = util.cos_sim(img_emb, text_emb)
    print("The final CLIP R-Precision is:", cos_scores[0][0].cpu().numpy())
